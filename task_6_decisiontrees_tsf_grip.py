# -*- coding: utf-8 -*-
"""Task #6 DecisionTrees TSF GRIP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16f4qRy3ejLzWlLnxi3qc6zf0P8YjvudK

## **TSF GRIP Data Science & Business Analytics**

## Task 6 : Prediction using Decision Tree Algorithm (Level - Intermediate)


*   Create the Decision Tree classifier and visualize it graphically.
*   The purpose is if we feed any new data to this classifier, it would be able to predict the right class accordingly.
*   Dataset : https://bit.ly/3kXTdox

### Author: **ASHWANI PRASAD**
"""

# Loading the given Iris.csv dataset which I kept on my Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Importing libraries in Python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Loading the iris dataset as given in Task #6 description
Iris_data=pd.read_csv('/content/drive/MyDrive/Iris.csv')

#Checking top 10 records of the given dataset.
print(Iris_data.head(5))

#Basic information regarding the data
Iris_data.info()

#Describe function gives the basic numerical info about data for each numeric feature..
Iris_data.describe()

#Data points count value for each class labels..
Iris_data.Species.value_counts()

"""**Visualizing Iris Data**"""

#Visualizing the dataset features to find pattern to solve our task

plt.scatter(Iris_data['SepalLengthCm'], Iris_data['SepalWidthCm'])
plt.show()

#Using Seaborn library to visualize 2 features based on target variable.

sns.set_style('whitegrid')
sns.FacetGrid(Iris_data, hue = 'Species')\
    .map(plt.scatter, 'SepalLengthCm', 'SepalWidthCm') \
    .add_legend()

plt.show()

#Pair plot gives the relationship between all features distribution with each other.

sns.pairplot(Iris_data.drop(['Id'], axis=1), hue='Species')
plt.show()

"""**Exploring Some New Features**"""

Iris_data['Sepal_diff'] = Iris_data['SepalLengthCm'] - Iris_data['SepalWidthCm']
Iris_data['Petal_diff'] = Iris_data['PetalLengthCm'] - Iris_data['PetalWidthCm']

Iris_data['Sepal_petal_len_diff'] = Iris_data['SepalLengthCm'] - Iris_data['PetalLengthCm']
Iris_data['Sepal_petal_width_diff'] = Iris_data['SepalWidthCm'] - Iris_data['PetalWidthCm']

Iris_data['Sepal_petal_len_width_diff'] = Iris_data['SepalLengthCm'] - Iris_data['PetalWidthCm']
Iris_data['Sepal_petal_width_len_diff'] = Iris_data['SepalWidthCm'] - Iris_data['PetalLengthCm']
Iris_data

#Finding relationship between new features based on class labels...

sns.pairplot(Iris_data[['Species', 'Sepal_diff', 'Petal_diff', 'Sepal_petal_len_diff', 
                        'Sepal_petal_width_diff','Sepal_petal_len_width_diff','Sepal_petal_width_len_diff']], hue='Species')
plt.show()

"""**Building Classification Model based on DECISION TREE ALGORITHM**"""

# Droping Id column as it is of no use in classifying the class labels..
Iris_data.drop(['Id'], axis=1,inplace=True)

#Importing few libraries for creating Decision Tree Classifier and visualizing the tree structure
from sklearn import tree
import graphviz
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score

# Import necessary library for graph viz  
from sklearn.tree import export_graphviz

# Seperating independant variables or target variables from Iris dataset
X = Iris_data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Sepal_petal_width_len_diff', 'Sepal_petal_width_diff', 'Sepal_petal_len_width_diff', 'Sepal_petal_len_diff']]
y = Iris_data['Species']

#Before training the model we have to split our data into Actual Train and Actual Test Dataset for training and validating purpose..
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.30, random_state=42)

#Splitting data into validation train and validation test
Xt, Xcv, Yt, Ycv = train_test_split(Xtrain, Ytrain, test_size=0.10, random_state=42)

#Now we create a Decision Tree Classifier and train it with training dataset
Iris_clf = DecisionTreeClassifier(criterion='gini', min_samples_split=2)
Iris_clf.fit(Xt, Yt)
print('Decision Tree Classifer Created')

"""### Let us visualize the Decision Tree to understand it better."""

# #Visualize the Decision Tree which is formed on train dataset
dot_data = tree.export_graphviz(Iris_clf, out_file=None,  
                filled=True, rounded=True,
                special_characters=True)
graph = graphviz.Source(dot_data) 
graph

"""**Validating our Decision Tree using cross validation method**"""

#As our model has been trained...
#Now we can validate our Decision Tree Using cross Validation method to get the accuracy or performance score of our model
print('Accuracy score is: ',cross_val_score(Iris_clf, Xt, Yt, cv=3, scoring='accuracy').mean()*100, '%')

#Checking validation test data on our trained model and getting performance mentrics

from sklearn.metrics import multilabel_confusion_matrix, accuracy_score
Y_hat = Iris_clf.predict(Xcv)

print('Accuracy score for validation test data is:', accuracy_score(Ycv, Y_hat)*100, '%')
multilabel_confusion_matrix(Ycv, Y_hat)

#Checking our model performance on actual unseen test data..
YT_hat = Iris_clf.predict(Xtest)
YT_hat

print('Model Accuracy Score on totally unseen data(Xtest) is :', accuracy_score(Ytest, YT_hat)*100, '%')
multilabel_confusion_matrix(Ytest, YT_hat)

"""**Training model on Actual Train Data**"""

Iris_Fclf=DecisionTreeClassifier(criterion='gini', min_samples_split=2)
Iris_Fclf.fit(Xtrain, Ytrain)

#Visualizing the final decision tree for deploying in real world cases...
dot_data = tree.export_graphviz(Iris_Fclf, out_file=None, filled=True, rounded=True,
                special_characters=True)
graph = graphviz.Source(dot_data)
graph

"""**Checking the performance of model on Actual Test data**"""

YT_Fhat = Iris_Fclf.predict(Xtest)
YT_hat

print('Model Accuracy Score on totally unseen data(Xtest) is: ', accuracy_score(Ytest, YT_Fhat)*100, '%')
multilabel_confusion_matrix(Ytest, YT_Fhat)

#Testing for New data points except from Dataset
import warnings
warnings.filterwarnings("ignore")
Test_point = [[5.4,3.0,4.5,1.5,-1.5,1.5, 2.0, 2.5],
             [6.5,2.8,4.6,1.5,-1.8,1.3, 3.5, 1.0],
             [5.1,2.5,3.0,1.1,-0.5,1.4, 4.3, 2.0],
             [5.1,3.3,1.7,0.5,1.6,2.8, 0.0, 1.5],
             [6.0,2.7,5.1,1.6,-2.4,1.1, 2.7, 6.0],
             [6.0,2.2,5.0,1.5,-2.8,0.7, 4.2, 1.9]]

print(Iris_Fclf.predict(Test_point))

"""# THE END"""